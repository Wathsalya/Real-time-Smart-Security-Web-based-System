import cv2
from flask import Flask, render_template, Response
#from datetime import datetime
from datetime import datetime, timedelta
import time
import requests
import numpy as np
# from matplotlib import pyplot as plt
import firebase_admin
from firebase_admin import credentials
from firebase_admin import storage
from firebase_admin import db
from flask_cors import CORS
import json

app = Flask(__name__)
CORS(app)


info = {"person":"Not detect",
        "ses":"",
        "det_img_url":"",
        "timeCount":""}

lim_1 = '06:00:00'  # 6 am
lim_2 = '13:00:00'  # 6 pm


def gen():
    global info,lim_1,lim_2

    databaseURL = 'https://motiondetectpro-default-rtdb.asia-southeast1.firebasedatabase.app/'

    cred_obj = firebase_admin.credentials.Certificate("motiondetectpro-firebase-adminsdk-xx63a-5842af1fd4.json")
    default_app = firebase_admin.initialize_app(cred_obj, {
        'databaseURL': databaseURL,
        'storageBucket': 'motiondetectpro.appspot.com'
    })

    bucket = storage.bucket()

    thres = 0.45

    video_capture = cv2.VideoCapture(0)

    classNames = []
    person = 0
    sendMsg = 0
    classFile = 'coco.names'
    with open(classFile, 'rt') as f:
        classNames = f.read().rstrip('\n').split('\n')

    configPath = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'
    weightsPath = 'frozen_inference_graph.pb'

    net = cv2.dnn_DetectionModel(weightsPath, configPath)
    net.setInputSize(320, 320)
    net.setInputScale(1.0 / 127.5)
    net.setInputMean((127.5, 127.5, 127.5))
    net.setInputSwapRB(True)
    tic = 0
    timeRef = 0



    while True:
        ret, image = video_capture.read()

        ret, frame1 = video_capture.read()
        ret, frame2 = video_capture.read()


        # success, img = cap.read()
        classIds, confs, bbox = net.detect(frame1, confThreshold=thres)

        now = datetime.now()
        current_time = now.strftime("%H:%M:%S")

        FMT = '%H:%M:%S'
        tdelta = datetime.strptime(current_time, FMT)
        t_lim_1 = datetime.strptime(lim_1, FMT)
        t_lim_2 = datetime.strptime(lim_2, FMT)

        if t_lim_1 < tdelta < t_lim_2:
            cv2.imwrite("fr.jpg", frame1)
            # ------------------------------------------day mode----------------------------------------
            # print("Current Time = day")
            info['ses'] = "Day"

            diff = cv2.absdiff(frame1, frame2)
            diff_gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
            blur = cv2.GaussianBlur(diff_gray, (5, 5), 0)
            _, thresh = cv2.threshold(blur, 20, 255, cv2.THRESH_BINARY)
            dilated = cv2.dilate(thresh, None, iterations=3)
            contours, _ = cv2.findContours(
                dilated, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

            for contour in contours:
                (x, y, w, h) = cv2.boundingRect(contour)
                # print(contour, "next")
                if cv2.contourArea(contour) < 900:
                    continue
                # cv2.rectangle(frame1, (x, y), (x + w, y + h), (0, 255, 0), 2)

                # cv2.putText(frame1, "Status: {}".format('Movement'), (10, 20), cv2.FONT_HERSHEY_SIMPLEX,
                           # 1, (255, 0, 0), 3)

                if len(classIds) != 0:
                    for classId, confidence, box in zip(classIds.flatten(), confs.flatten(), bbox):

                        # cv.putText(frame1, str(round(confidence * 100, 2)), (box[0] + 200, box[1] + 30),
                        # cv.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)
                        # qq = 'person'
                        if classNames[classId - 1] == 'person':


                            info['person'] = "detect"


                            now = datetime.now()
                            timestamp = datetime.timestamp(now)

                            cv2.rectangle(frame1, box, color=(0, 0, 255), thickness=2)
                            # cv2.putText(frame1, classNames[classId - 1].upper(), (box[0] + 10, box[1] + 20),
                                       # cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)

                            # cv.imwrite("%f.jpg" % timestamp, frame1)
                            cv2.imwrite("fr.jpg", frame1)
                            # cv2.imshow('frame', frame)
                            # print("human")
                            # print(classNames[classId - 1])
                            person += 1

            # cv.drawContours(frame1, contours, -1, (0, 255, 0), 2)

            # cv2.imshow("Videotedt", frame1)
            # cv.imshow("Video2", diff_gray)
            # frame1 = frame2
            # ret, frame2 = video_capture.read()

            if person > 5 and sendMsg == 0:
                # cv.imwrite("%f.jpg" % timestamp, frame1)
                cv2.imwrite("ref.jpg", frame1)
                img_url = 'ref.jpg'
                img_url1 = ('%f.jpg' % timestamp)
                img_url2 = ('images/%f.jpg' % timestamp)
                print("upload")
                # upload to firebase ------------------------------
                blob = bucket.blob(img_url)
                outfile = img_url
                blob.upload_from_filename(outfile)

                blob = bucket.blob(img_url2)
                outfile = img_url
                blob.upload_from_filename(outfile)

                bucket = storage.bucket(app=default_app)
                blob = bucket.blob(img_url2)

                info['det_img_url'] = blob.generate_signed_url(timedelta(seconds=600), method='GET')
                # print(_url)

                # ref = db.reference("/")
                # ref.push().set({
                # "Type": classNames[classId - 1],
                # "timestamp": timestamp,
                # "image": img_url1,
                # "run": "now"

                # })

                sendMsg = 1
                print("send msg", person)
                # SMS API---------------------------
                # response = requests.get("https://app.smsapi.lk/sms/api?action=send-sms&api_key=Qnh3dGFyeUlwQk9Od0FESmpzRnY=&to=94719499838&from=Ticketz&sms=SecurityBreachDirected")
                # print(response)

            tic = time.perf_counter()
            # print(f" {tic - timeRef:0.4f}")
            info['timeCount'] = round(tic, 2) - round(timeRef, 2)
            if tic - timeRef > 20:  # 20 min - delay for next msg and upload
                sendMsg = 0
                person = 0
                timeRef = tic

                info['person'] = "No Security Threat"

            # if cv2.waitKey(50) == 27:
            # break
        else:
            # ------------------------------------------night mode----------------------------------------
            # print("Current Time = night")
            info['ses'] = "Night"

            t1 = cv2.cvtColor(video_capture.read()[1], cv2.COLOR_RGB2GRAY)
            t = cv2.cvtColor(video_capture.read()[1], cv2.COLOR_RGB2GRAY)
            t2 = cv2.cvtColor(video_capture.read()[1], cv2.COLOR_RGB2GRAY)


            # cv2.imshow(winName, diffImg(t1, t, t2))
            diff = cv2.absdiff(t1, t, t2)

            alpha = 1.95  # Contrast control (1.0-3.0)
            beta = 50  # Brightness control (0-100)

            m_result = cv2.convertScaleAbs(diff, alpha=alpha, beta=beta)

            # t1 = t
            # t = t2
            # t2 = cv2.cvtColor(video_capture.read()[1], cv2.COLOR_RGB2GRAY)

            frame1 = m_result

        cv2.imwrite('fr.jpg', frame1)
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + open('fr.jpg', 'rb').read() + b'\r\n')
    video_capture.release()


@app.route('/')
def index():
    """Video streaming"""
    return render_template('index.html')


@app.route('/video_feed')
def video_feed():
    """Video streaming route. Put this in the src attribute of an img tag."""
    return Response(gen(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')




@app.route('/info', methods=['GET'])
def data():

    return info


if __name__ == '__main__':
    app.run()
